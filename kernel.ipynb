{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitri/anaconda3/envs/Tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/home/dmitri/anaconda3/envs/Tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/dmitri/anaconda3/envs/Tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/dmitri/anaconda3/envs/Tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/dmitri/anaconda3/envs/Tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq # Used to read the data\n",
    "import os \n",
    "import numpy as np\n",
    "from keras.layers import * # Keras is the most friendly Neural Network library, this Kernel use a lot of layers classes\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm # Processing time measurement\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras import backend as K # The backend give us access to tensorflow operations and allow us to create the Attention class\n",
    "from keras import optimizers # Allow us to access the Adam class to modify some parameters\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold # Used to use Kfold to train our model\n",
    "from keras.callbacks import * # This object helps the model to train in a smarter way, avoiding overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select how many folds will be created\n",
    "N_SPLITS = 5\n",
    "# it is just a constant with the measurements data size\n",
    "sample_size = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is the official metric used in this competition\n",
    "# below is the declaration of a function used inside the keras model, calculation with K (keras backend / thensorflow)\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    '''Calculates the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    '''\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      signal_id  target\n",
       "id_measurement phase                   \n",
       "0              0              0       0\n",
       "               1              1       0\n",
       "               2              2       0\n",
       "1              0              3       1\n",
       "               1              4       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just load train data\n",
    "df_train = pd.read_csv('../input/metadata_train.csv')\n",
    "# set index, it makes the data access much faster\n",
    "df_train = df_train.set_index(['id_measurement', 'phase'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in other notebook I have extracted the min and max values from the train data, the measurements\n",
    "max_num = 127\n",
    "min_num = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function standardize the data from (-128 to 127) to (-1 to 1)\n",
    "# Theoretically it helps in the NN Model training, but I didn't tested without it\n",
    "def min_max_transf(ts, min_data, max_data, range_needed=(-1,1)):\n",
    "    if min_data < 0:\n",
    "        ts_std = (ts + abs(min_data)) / (max_data + abs(min_data))\n",
    "    else:\n",
    "        ts_std = (ts - min_data) / (max_data - min_data)\n",
    "    if range_needed[0] < 0:    \n",
    "        return ts_std * (range_needed[1] + abs(range_needed[0])) + range_needed[0]\n",
    "    else:\n",
    "        return ts_std * (range_needed[1] - range_needed[0]) + range_needed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one of the most important peace of code of this Kernel\n",
    "# Any power line contain 3 phases of 800000 measurements, or 2.4 millions data \n",
    "# It would be praticaly impossible to build a NN with an input of that size\n",
    "# The ideia here is to reduce it each phase to a matrix of <n_dim> bins by n features\n",
    "# Each bean is a set of 5000 measurements (800000 / 160), so the features are extracted from this 5000 chunk data.\n",
    "def transform_ts(ts, n_dim=160, min_max=(-1,1)):\n",
    "    # convert data into -1 to 1\n",
    "    ts_std = min_max_transf(ts, min_data=min_num, max_data=max_num)\n",
    "    # bucket or chunk size, 5000 in this case (800000 / 160)\n",
    "    bucket_size = int(sample_size / n_dim)\n",
    "    # new_ts will be the container of the new data\n",
    "    new_ts = []\n",
    "    # this for iteract any chunk/bucket until reach the whole sample_size (800000)\n",
    "    for i in range(0, sample_size, bucket_size):\n",
    "        # cut each bucket to ts_range\n",
    "        ts_range = ts_std[i:i + bucket_size]\n",
    "        # calculate each feature\n",
    "        mean = ts_range.mean()\n",
    "        std = ts_range.std() # standard deviation\n",
    "        std_top = mean + std # I have to test it more, but is is like a band\n",
    "        std_bot = mean - std\n",
    "        # I think that the percentiles are very important, it is like a distribuiton analysis from eath chunk\n",
    "        percentil_calc = np.percentile(ts_range, [0, 1, 25, 50, 75, 99, 100]) \n",
    "        max_range = percentil_calc[-1] - percentil_calc[0] # this is the amplitude of the chunk\n",
    "        relative_percentile = percentil_calc - mean # maybe it could heap to understand the asymmetry\n",
    "        # now, we just add all the features to new_ts and convert it to np.array\n",
    "        new_ts.append(np.concatenate([np.asarray([mean, std, std_top, std_bot, max_range]),percentil_calc, relative_percentile]))\n",
    "    return np.asarray(new_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function take a piece of data and convert using transform_ts(), but it does to each of the 3 phases\n",
    "# if we would try to do in one time, could exceed the RAM Memmory\n",
    "def prep_data(start, end):\n",
    "    # load a piece of data from file\n",
    "    praq_train = pq.read_pandas('../input/train.parquet', columns=[str(i) for i in range(start, end)]).to_pandas()\n",
    "    X = []\n",
    "    y = []\n",
    "    # using tdqm to evaluate processing time\n",
    "    # takes each index from df_train and iteract it from start to end\n",
    "    # it is divided by 3 because for each id_measurement there are 3 id_signal, and the start/end parameters are id_signal\n",
    "    for id_measurement in tqdm(df_train.index.levels[0].unique()[int(start/3):int(end/3)]):\n",
    "        X_signal = []\n",
    "        # for each phase of the signal\n",
    "        for phase in [0,1,2]:\n",
    "            # extract from df_train both signal_id and target to compose the new data sets\n",
    "            signal_id, target = df_train.loc[id_measurement].loc[phase]\n",
    "            # but just append the target one time, to not triplicate it\n",
    "            if phase == 0:\n",
    "                y.append(target)\n",
    "            # extract and transform data into sets of features\n",
    "            X_signal.append(transform_ts(praq_train[str(signal_id)]))\n",
    "        # concatenate all the 3 phases in one matrix\n",
    "        X_signal = np.concatenate(X_signal, axis=1)\n",
    "        # add the data to X\n",
    "        X.append(X_signal)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1452/1452 [04:04<00:00,  5.94it/s]\n",
      "100%|██████████| 1452/1452 [03:57<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# this code is very simple, divide the total size of the df_train into two sets and process it\n",
    "X = []\n",
    "y = []\n",
    "def load_all():\n",
    "    total_size = len(df_train)\n",
    "    for ini, end in [(0, int(total_size/2)), (int(total_size/2), total_size)]:\n",
    "        X_temp, y_temp = prep_data(ini, end)\n",
    "        X.append(X_temp)\n",
    "        y.append(y_temp)\n",
    "load_all()\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2904, 160, 57) (2904,)\n"
     ]
    }
   ],
   "source": [
    "# The X shape here is very important. It is also important undertand a little how a LSTM works\n",
    "# X.shape[0] is the number of id_measuremts contained in train data\n",
    "# X.shape[1] is the number of chunks resultant of the transformation, each of this date enters in the LSTM serialized\n",
    "# This way the LSTM can understand the position of a data relative with other and activate a signal that needs\n",
    "# a serie of inputs in a specifc order.\n",
    "# X.shape[3] is the number of features multiplied by the number of phases (3)\n",
    "print(X.shape, y.shape)\n",
    "# save data into file, a numpy specific format\n",
    "np.save(\"X.npy\",X)\n",
    "np.save(\"y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is NN LSTM Model creation\n",
    "def model_lstm(input_shape):\n",
    "    # The shape was explained above, must have this order\n",
    "    inp = Input(shape=(input_shape[1], input_shape[2],))\n",
    "    # This is the LSTM layer\n",
    "    # Bidirecional implies that the 160 chunks are calculated in both ways, 0 to 159 and 159 to zero\n",
    "    # although it appear that just 0 to 159 way matter, I have tested with and without, and tha later worked best\n",
    "    # 128 and 64 are the number of cells used, too many can overfit and too few can underfit\n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(inp)\n",
    "    # The second LSTM can give more fire power to the model, but can overfit it too\n",
    "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "    # Attention is a new tecnology that can be applyed to a Recurrent NN to give more meanings to a signal found in the middle\n",
    "    # of the data, it helps more in longs chains of data. A normal RNN give all the responsibility of detect the signal\n",
    "    # to the last cell. Google RNN Attention for more information :)\n",
    "    x = Attention(input_shape[1])(x)\n",
    "    # A intermediate full connected (Dense) can help to deal with nonlinears outputs\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    # A binnary classification as this must finish with shape (1,)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    # Pay attention in the addition of matthews_correlation metric in the compilation, it is a success factor key\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[matthews_correlation])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning fold 1\n",
      "Train on 2322 samples, validate on 582 samples\n",
      "Epoch 1/50\n",
      "2322/2322 [==============================] - 5s 2ms/step - loss: 0.3530 - matthews_correlation: 0.0000e+00 - val_loss: 0.2310 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_0.h5\n",
      "Epoch 2/50\n",
      "2322/2322 [==============================] - 1s 367us/step - loss: 0.2314 - matthews_correlation: 0.0000e+00 - val_loss: 0.2279 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2322/2322 [==============================] - 1s 346us/step - loss: 0.2153 - matthews_correlation: 0.0000e+00 - val_loss: 0.2147 - val_matthews_correlation: 0.1583\n",
      "\n",
      "Epoch 00003: val_matthews_correlation improved from 0.00000 to 0.15834, saving model to weights_0.h5\n",
      "Epoch 4/50\n",
      "2322/2322 [==============================] - 1s 336us/step - loss: 0.2079 - matthews_correlation: 0.1456 - val_loss: 0.1885 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.15834\n",
      "Epoch 5/50\n",
      "2322/2322 [==============================] - 1s 332us/step - loss: 0.2035 - matthews_correlation: 0.0746 - val_loss: 0.2064 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.15834\n",
      "Epoch 6/50\n",
      "2322/2322 [==============================] - 1s 348us/step - loss: 0.1970 - matthews_correlation: 0.2780 - val_loss: 0.1901 - val_matthews_correlation: 0.1923\n",
      "\n",
      "Epoch 00006: val_matthews_correlation improved from 0.15834 to 0.19231, saving model to weights_0.h5\n",
      "Epoch 7/50\n",
      "2322/2322 [==============================] - 1s 337us/step - loss: 0.1713 - matthews_correlation: 0.2484 - val_loss: 0.1350 - val_matthews_correlation: 0.1923\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.19231\n",
      "Epoch 8/50\n",
      "2322/2322 [==============================] - 1s 337us/step - loss: 0.1488 - matthews_correlation: 0.4109 - val_loss: 0.1077 - val_matthews_correlation: 0.3886\n",
      "\n",
      "Epoch 00008: val_matthews_correlation improved from 0.19231 to 0.38859, saving model to weights_0.h5\n",
      "Epoch 9/50\n",
      "2322/2322 [==============================] - 1s 346us/step - loss: 0.1226 - matthews_correlation: 0.5072 - val_loss: 0.1005 - val_matthews_correlation: 0.4996\n",
      "\n",
      "Epoch 00009: val_matthews_correlation improved from 0.38859 to 0.49956, saving model to weights_0.h5\n",
      "Epoch 10/50\n",
      "2322/2322 [==============================] - 1s 336us/step - loss: 0.1343 - matthews_correlation: 0.4400 - val_loss: 0.1158 - val_matthews_correlation: 0.7016\n",
      "\n",
      "Epoch 00010: val_matthews_correlation improved from 0.49956 to 0.70164, saving model to weights_0.h5\n",
      "Epoch 11/50\n",
      "2322/2322 [==============================] - 1s 336us/step - loss: 0.1162 - matthews_correlation: 0.5841 - val_loss: 0.1112 - val_matthews_correlation: 0.4142\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.70164\n",
      "Epoch 12/50\n",
      "2322/2322 [==============================] - 1s 350us/step - loss: 0.1132 - matthews_correlation: 0.5867 - val_loss: 0.0987 - val_matthews_correlation: 0.7439\n",
      "\n",
      "Epoch 00012: val_matthews_correlation improved from 0.70164 to 0.74386, saving model to weights_0.h5\n",
      "Epoch 13/50\n",
      "2322/2322 [==============================] - 1s 332us/step - loss: 0.1091 - matthews_correlation: 0.6043 - val_loss: 0.0743 - val_matthews_correlation: 0.7846\n",
      "\n",
      "Epoch 00013: val_matthews_correlation improved from 0.74386 to 0.78458, saving model to weights_0.h5\n",
      "Epoch 14/50\n",
      "2322/2322 [==============================] - 1s 336us/step - loss: 0.1067 - matthews_correlation: 0.6378 - val_loss: 0.0781 - val_matthews_correlation: 0.7605\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.78458\n",
      "Epoch 15/50\n",
      "2322/2322 [==============================] - 1s 336us/step - loss: 0.1062 - matthews_correlation: 0.5704 - val_loss: 0.0961 - val_matthews_correlation: 0.7422\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.78458\n",
      "Epoch 16/50\n",
      "2322/2322 [==============================] - 1s 332us/step - loss: 0.1068 - matthews_correlation: 0.6438 - val_loss: 0.0921 - val_matthews_correlation: 0.6521\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.78458\n",
      "Epoch 17/50\n",
      "2322/2322 [==============================] - 1s 348us/step - loss: 0.1054 - matthews_correlation: 0.6081 - val_loss: 0.0798 - val_matthews_correlation: 0.7938\n",
      "\n",
      "Epoch 00017: val_matthews_correlation improved from 0.78458 to 0.79383, saving model to weights_0.h5\n",
      "Epoch 18/50\n",
      "2322/2322 [==============================] - 1s 333us/step - loss: 0.1042 - matthews_correlation: 0.6389 - val_loss: 0.0788 - val_matthews_correlation: 0.8178\n",
      "\n",
      "Epoch 00018: val_matthews_correlation improved from 0.79383 to 0.81785, saving model to weights_0.h5\n",
      "Epoch 19/50\n",
      "2322/2322 [==============================] - 1s 346us/step - loss: 0.1053 - matthews_correlation: 0.6401 - val_loss: 0.0724 - val_matthews_correlation: 0.7509\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.81785\n",
      "Epoch 20/50\n",
      "2322/2322 [==============================] - 1s 334us/step - loss: 0.1014 - matthews_correlation: 0.6538 - val_loss: 0.0754 - val_matthews_correlation: 0.8008\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.81785\n",
      "Epoch 21/50\n",
      "2322/2322 [==============================] - 1s 349us/step - loss: 0.0984 - matthews_correlation: 0.6793 - val_loss: 0.0744 - val_matthews_correlation: 0.7627\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.81785\n",
      "Epoch 22/50\n",
      "2322/2322 [==============================] - 1s 331us/step - loss: 0.1013 - matthews_correlation: 0.6715 - val_loss: 0.0847 - val_matthews_correlation: 0.7855\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.81785\n",
      "Epoch 23/50\n",
      "2322/2322 [==============================] - 1s 357us/step - loss: 0.1032 - matthews_correlation: 0.6294 - val_loss: 0.0733 - val_matthews_correlation: 0.7743\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.81785\n",
      "Epoch 24/50\n",
      "2322/2322 [==============================] - 1s 372us/step - loss: 0.1041 - matthews_correlation: 0.6424 - val_loss: 0.0953 - val_matthews_correlation: 0.5139\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.81785\n",
      "Epoch 25/50\n",
      "2322/2322 [==============================] - 1s 359us/step - loss: 0.1015 - matthews_correlation: 0.5846 - val_loss: 0.0766 - val_matthews_correlation: 0.7742\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.81785\n",
      "Epoch 26/50\n",
      "2322/2322 [==============================] - 1s 335us/step - loss: 0.0967 - matthews_correlation: 0.6961 - val_loss: 0.0749 - val_matthews_correlation: 0.8460\n",
      "\n",
      "Epoch 00026: val_matthews_correlation improved from 0.81785 to 0.84605, saving model to weights_0.h5\n",
      "Epoch 27/50\n",
      "2322/2322 [==============================] - 1s 341us/step - loss: 0.0997 - matthews_correlation: 0.5854 - val_loss: 0.0752 - val_matthews_correlation: 0.7605\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 28/50\n",
      "2322/2322 [==============================] - 1s 343us/step - loss: 0.0950 - matthews_correlation: 0.6595 - val_loss: 0.0779 - val_matthews_correlation: 0.7832\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 29/50\n",
      "2322/2322 [==============================] - 1s 346us/step - loss: 0.0933 - matthews_correlation: 0.6752 - val_loss: 0.0784 - val_matthews_correlation: 0.7213\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 30/50\n",
      "2322/2322 [==============================] - 1s 347us/step - loss: 0.0921 - matthews_correlation: 0.6944 - val_loss: 0.0715 - val_matthews_correlation: 0.7399\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 31/50\n",
      "2322/2322 [==============================] - 1s 350us/step - loss: 0.0914 - matthews_correlation: 0.6865 - val_loss: 0.0786 - val_matthews_correlation: 0.7605\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 32/50\n",
      "2322/2322 [==============================] - 1s 338us/step - loss: 0.0926 - matthews_correlation: 0.6722 - val_loss: 0.0865 - val_matthews_correlation: 0.7317\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2322/2322 [==============================] - 1s 353us/step - loss: 0.0932 - matthews_correlation: 0.6665 - val_loss: 0.0689 - val_matthews_correlation: 0.7716\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 34/50\n",
      "2322/2322 [==============================] - 1s 348us/step - loss: 0.0894 - matthews_correlation: 0.6511 - val_loss: 0.0686 - val_matthews_correlation: 0.7816\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 35/50\n",
      "2322/2322 [==============================] - 1s 330us/step - loss: 0.0918 - matthews_correlation: 0.6938 - val_loss: 0.0778 - val_matthews_correlation: 0.7464\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 36/50\n",
      "2322/2322 [==============================] - 1s 332us/step - loss: 0.0953 - matthews_correlation: 0.6690 - val_loss: 0.0874 - val_matthews_correlation: 0.7856\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 37/50\n",
      "2322/2322 [==============================] - 1s 346us/step - loss: 0.0927 - matthews_correlation: 0.6621 - val_loss: 0.0810 - val_matthews_correlation: 0.7819\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 38/50\n",
      "2322/2322 [==============================] - 1s 332us/step - loss: 0.0864 - matthews_correlation: 0.6944 - val_loss: 0.0875 - val_matthews_correlation: 0.7584\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 39/50\n",
      "2322/2322 [==============================] - 1s 333us/step - loss: 0.0910 - matthews_correlation: 0.6756 - val_loss: 0.0798 - val_matthews_correlation: 0.8271\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 40/50\n",
      "2322/2322 [==============================] - 1s 333us/step - loss: 0.0927 - matthews_correlation: 0.6665 - val_loss: 0.0701 - val_matthews_correlation: 0.7820\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 41/50\n",
      "2322/2322 [==============================] - 1s 347us/step - loss: 0.0863 - matthews_correlation: 0.6924 - val_loss: 0.0714 - val_matthews_correlation: 0.7567\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 42/50\n",
      "2322/2322 [==============================] - 1s 345us/step - loss: 0.0935 - matthews_correlation: 0.6580 - val_loss: 0.0809 - val_matthews_correlation: 0.7558\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 43/50\n",
      "2322/2322 [==============================] - 1s 340us/step - loss: 0.0863 - matthews_correlation: 0.7093 - val_loss: 0.0895 - val_matthews_correlation: 0.7628\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 44/50\n",
      "2322/2322 [==============================] - 1s 346us/step - loss: 0.0940 - matthews_correlation: 0.6584 - val_loss: 0.0749 - val_matthews_correlation: 0.8052\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 45/50\n",
      "2322/2322 [==============================] - 1s 334us/step - loss: 0.0872 - matthews_correlation: 0.7072 - val_loss: 0.0826 - val_matthews_correlation: 0.7284\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 46/50\n",
      "2322/2322 [==============================] - 1s 332us/step - loss: 0.0819 - matthews_correlation: 0.7066 - val_loss: 0.0788 - val_matthews_correlation: 0.8258\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 47/50\n",
      "2322/2322 [==============================] - 1s 361us/step - loss: 0.0792 - matthews_correlation: 0.6880 - val_loss: 0.0814 - val_matthews_correlation: 0.7898\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 48/50\n",
      "2322/2322 [==============================] - 1s 331us/step - loss: 0.0772 - matthews_correlation: 0.7089 - val_loss: 0.0928 - val_matthews_correlation: 0.7835\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 49/50\n",
      "2322/2322 [==============================] - 1s 346us/step - loss: 0.0900 - matthews_correlation: 0.7345 - val_loss: 0.0852 - val_matthews_correlation: 0.7659\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.84605\n",
      "Epoch 50/50\n",
      "2322/2322 [==============================] - 1s 333us/step - loss: 0.0906 - matthews_correlation: 0.7001 - val_loss: 0.0832 - val_matthews_correlation: 0.7628\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.84605\n",
      "Beginning fold 2\n",
      "Train on 2323 samples, validate on 581 samples\n",
      "Epoch 1/50\n",
      "2323/2323 [==============================] - 2s 662us/step - loss: 0.3522 - matthews_correlation: 0.0000e+00 - val_loss: 0.2422 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_1.h5\n",
      "Epoch 2/50\n",
      "2323/2323 [==============================] - 1s 340us/step - loss: 0.2294 - matthews_correlation: 0.0000e+00 - val_loss: 0.2317 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2323/2323 [==============================] - 1s 338us/step - loss: 0.2227 - matthews_correlation: 0.0000e+00 - val_loss: 0.2207 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/50\n",
      "2323/2323 [==============================] - 1s 337us/step - loss: 0.2073 - matthews_correlation: 0.0000e+00 - val_loss: 0.2081 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/50\n",
      "2323/2323 [==============================] - 1s 335us/step - loss: 0.1965 - matthews_correlation: 0.1481 - val_loss: 0.2121 - val_matthews_correlation: -0.0071\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 6/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1906 - matthews_correlation: 0.1419 - val_loss: 0.1787 - val_matthews_correlation: 0.1045\n",
      "\n",
      "Epoch 00006: val_matthews_correlation improved from 0.00000 to 0.10453, saving model to weights_1.h5\n",
      "Epoch 7/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1707 - matthews_correlation: 0.1921 - val_loss: 0.1730 - val_matthews_correlation: 0.0806\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.10453\n",
      "Epoch 8/50\n",
      "2323/2323 [==============================] - 1s 334us/step - loss: 0.1525 - matthews_correlation: 0.2988 - val_loss: 0.1718 - val_matthews_correlation: 0.4711\n",
      "\n",
      "Epoch 00008: val_matthews_correlation improved from 0.10453 to 0.47111, saving model to weights_1.h5\n",
      "Epoch 9/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1727 - matthews_correlation: 0.2721 - val_loss: 0.1909 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_matthews_correlation did not improve from 0.47111\n",
      "Epoch 10/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1570 - matthews_correlation: 0.2229 - val_loss: 0.1332 - val_matthews_correlation: 0.5752\n",
      "\n",
      "Epoch 00010: val_matthews_correlation improved from 0.47111 to 0.57516, saving model to weights_1.h5\n",
      "Epoch 11/50\n",
      "2323/2323 [==============================] - 1s 336us/step - loss: 0.1128 - matthews_correlation: 0.4934 - val_loss: 0.1112 - val_matthews_correlation: 0.6209\n",
      "\n",
      "Epoch 00011: val_matthews_correlation improved from 0.57516 to 0.62091, saving model to weights_1.h5\n",
      "Epoch 12/50\n",
      "2323/2323 [==============================] - 1s 338us/step - loss: 0.1089 - matthews_correlation: 0.5979 - val_loss: 0.1193 - val_matthews_correlation: 0.6731\n",
      "\n",
      "Epoch 00012: val_matthews_correlation improved from 0.62091 to 0.67314, saving model to weights_1.h5\n",
      "Epoch 13/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1193 - matthews_correlation: 0.5203 - val_loss: 0.1061 - val_matthews_correlation: 0.6731\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.67314\n",
      "Epoch 14/50\n",
      "2323/2323 [==============================] - 1s 335us/step - loss: 0.1008 - matthews_correlation: 0.6787 - val_loss: 0.1089 - val_matthews_correlation: 0.6834\n",
      "\n",
      "Epoch 00014: val_matthews_correlation improved from 0.67314 to 0.68336, saving model to weights_1.h5\n",
      "Epoch 15/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.1037 - matthews_correlation: 0.6655 - val_loss: 0.1071 - val_matthews_correlation: 0.6490\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2323/2323 [==============================] - 1s 334us/step - loss: 0.1079 - matthews_correlation: 0.6791 - val_loss: 0.1144 - val_matthews_correlation: 0.6189\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 17/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0985 - matthews_correlation: 0.6812 - val_loss: 0.1114 - val_matthews_correlation: 0.6115\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 18/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0972 - matthews_correlation: 0.6995 - val_loss: 0.1089 - val_matthews_correlation: 0.6383\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 19/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0954 - matthews_correlation: 0.6969 - val_loss: 0.1101 - val_matthews_correlation: 0.6281\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 20/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1014 - matthews_correlation: 0.6301 - val_loss: 0.1049 - val_matthews_correlation: 0.6588\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 21/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0930 - matthews_correlation: 0.6879 - val_loss: 0.1119 - val_matthews_correlation: 0.6196\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 22/50\n",
      "2323/2323 [==============================] - 1s 342us/step - loss: 0.0943 - matthews_correlation: 0.6912 - val_loss: 0.1063 - val_matthews_correlation: 0.6361\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 23/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0920 - matthews_correlation: 0.6976 - val_loss: 0.1073 - val_matthews_correlation: 0.6015\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 24/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0945 - matthews_correlation: 0.6619 - val_loss: 0.1093 - val_matthews_correlation: 0.6397\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 25/50\n",
      "2323/2323 [==============================] - 1s 336us/step - loss: 0.0993 - matthews_correlation: 0.6871 - val_loss: 0.1026 - val_matthews_correlation: 0.6322\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 26/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0966 - matthews_correlation: 0.6775 - val_loss: 0.1074 - val_matthews_correlation: 0.6459\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 27/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1050 - matthews_correlation: 0.6531 - val_loss: 0.1044 - val_matthews_correlation: 0.6447\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 28/50\n",
      "2323/2323 [==============================] - 1s 335us/step - loss: 0.0941 - matthews_correlation: 0.7124 - val_loss: 0.1119 - val_matthews_correlation: 0.6189\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 29/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1059 - matthews_correlation: 0.5640 - val_loss: 0.1050 - val_matthews_correlation: 0.6470\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 30/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0957 - matthews_correlation: 0.6743 - val_loss: 0.1097 - val_matthews_correlation: 0.6647\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 31/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0959 - matthews_correlation: 0.6810 - val_loss: 0.1062 - val_matthews_correlation: 0.6197\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 32/50\n",
      "2323/2323 [==============================] - 1s 330us/step - loss: 0.0969 - matthews_correlation: 0.6843 - val_loss: 0.1070 - val_matthews_correlation: 0.6584\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 33/50\n",
      "2323/2323 [==============================] - 1s 330us/step - loss: 0.0927 - matthews_correlation: 0.6942 - val_loss: 0.1069 - val_matthews_correlation: 0.6489\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 34/50\n",
      "2323/2323 [==============================] - 1s 330us/step - loss: 0.0908 - matthews_correlation: 0.6892 - val_loss: 0.1085 - val_matthews_correlation: 0.6341\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 35/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.1005 - matthews_correlation: 0.6640 - val_loss: 0.1119 - val_matthews_correlation: 0.6470\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 36/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0937 - matthews_correlation: 0.6897 - val_loss: 0.1178 - val_matthews_correlation: 0.6532\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 37/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0955 - matthews_correlation: 0.6623 - val_loss: 0.1121 - val_matthews_correlation: 0.6353\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 38/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0884 - matthews_correlation: 0.6875 - val_loss: 0.1093 - val_matthews_correlation: 0.6335\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 39/50\n",
      "2323/2323 [==============================] - 1s 335us/step - loss: 0.0895 - matthews_correlation: 0.7093 - val_loss: 0.1186 - val_matthews_correlation: 0.6216\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 40/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0930 - matthews_correlation: 0.6605 - val_loss: 0.1048 - val_matthews_correlation: 0.6507\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 41/50\n",
      "2323/2323 [==============================] - 1s 328us/step - loss: 0.1006 - matthews_correlation: 0.6114 - val_loss: 0.1121 - val_matthews_correlation: 0.5852\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 42/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0854 - matthews_correlation: 0.6783 - val_loss: 0.1056 - val_matthews_correlation: 0.6555\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 43/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0902 - matthews_correlation: 0.6293 - val_loss: 0.1110 - val_matthews_correlation: 0.5829\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 44/50\n",
      "2323/2323 [==============================] - 1s 329us/step - loss: 0.0895 - matthews_correlation: 0.6892 - val_loss: 0.1142 - val_matthews_correlation: 0.6216\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 45/50\n",
      "2323/2323 [==============================] - 1s 335us/step - loss: 0.0874 - matthews_correlation: 0.6989 - val_loss: 0.1237 - val_matthews_correlation: 0.5893\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 46/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0865 - matthews_correlation: 0.7168 - val_loss: 0.1097 - val_matthews_correlation: 0.6032\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 47/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0850 - matthews_correlation: 0.7168 - val_loss: 0.1111 - val_matthews_correlation: 0.6100\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 48/50\n",
      "2323/2323 [==============================] - 1s 329us/step - loss: 0.0825 - matthews_correlation: 0.6947 - val_loss: 0.1163 - val_matthews_correlation: 0.6294\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 49/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0833 - matthews_correlation: 0.7180 - val_loss: 0.1263 - val_matthews_correlation: 0.6049\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.68336\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0905 - matthews_correlation: 0.6847 - val_loss: 0.1083 - val_matthews_correlation: 0.5989\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.68336\n",
      "Beginning fold 3\n",
      "Train on 2323 samples, validate on 581 samples\n",
      "Epoch 1/50\n",
      "2323/2323 [==============================] - 1s 622us/step - loss: 0.3381 - matthews_correlation: 0.0000e+00 - val_loss: 0.2226 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_2.h5\n",
      "Epoch 2/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.2162 - matthews_correlation: 0.0000e+00 - val_loss: 0.2198 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2323/2323 [==============================] - 1s 330us/step - loss: 0.1989 - matthews_correlation: 0.0232 - val_loss: 0.2025 - val_matthews_correlation: 0.3741\n",
      "\n",
      "Epoch 00003: val_matthews_correlation improved from 0.00000 to 0.37408, saving model to weights_2.h5\n",
      "Epoch 4/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.1889 - matthews_correlation: 0.1019 - val_loss: 0.1606 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.37408\n",
      "Epoch 5/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.1572 - matthews_correlation: 0.0669 - val_loss: 0.1465 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_matthews_correlation did not improve from 0.37408\n",
      "Epoch 6/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.1496 - matthews_correlation: 0.3540 - val_loss: 0.1213 - val_matthews_correlation: 0.5032\n",
      "\n",
      "Epoch 00006: val_matthews_correlation improved from 0.37408 to 0.50316, saving model to weights_2.h5\n",
      "Epoch 7/50\n",
      "2323/2323 [==============================] - 1s 329us/step - loss: 0.1202 - matthews_correlation: 0.5795 - val_loss: 0.1140 - val_matthews_correlation: 0.5557\n",
      "\n",
      "Epoch 00007: val_matthews_correlation improved from 0.50316 to 0.55570, saving model to weights_2.h5\n",
      "Epoch 8/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.1077 - matthews_correlation: 0.6074 - val_loss: 0.1302 - val_matthews_correlation: 0.3987\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.55570\n",
      "Epoch 9/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.1070 - matthews_correlation: 0.6262 - val_loss: 0.1349 - val_matthews_correlation: 0.6521\n",
      "\n",
      "Epoch 00009: val_matthews_correlation improved from 0.55570 to 0.65215, saving model to weights_2.h5\n",
      "Epoch 10/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.1058 - matthews_correlation: 0.6359 - val_loss: 0.1154 - val_matthews_correlation: 0.5569\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.65215\n",
      "Epoch 11/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.1021 - matthews_correlation: 0.6499 - val_loss: 0.1176 - val_matthews_correlation: 0.5623\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.65215\n",
      "Epoch 12/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1019 - matthews_correlation: 0.6511 - val_loss: 0.1457 - val_matthews_correlation: 0.6384\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.65215\n",
      "Epoch 13/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.1130 - matthews_correlation: 0.6154 - val_loss: 0.1097 - val_matthews_correlation: 0.6055\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.65215\n",
      "Epoch 14/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0976 - matthews_correlation: 0.6502 - val_loss: 0.1175 - val_matthews_correlation: 0.4829\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.65215\n",
      "Epoch 15/50\n",
      "2323/2323 [==============================] - 1s 335us/step - loss: 0.0966 - matthews_correlation: 0.6761 - val_loss: 0.1125 - val_matthews_correlation: 0.5361\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.65215\n",
      "Epoch 16/50\n",
      "2323/2323 [==============================] - 1s 335us/step - loss: 0.0933 - matthews_correlation: 0.6821 - val_loss: 0.1131 - val_matthews_correlation: 0.5776\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.65215\n",
      "Epoch 17/50\n",
      "2323/2323 [==============================] - 1s 335us/step - loss: 0.0913 - matthews_correlation: 0.7068 - val_loss: 0.1105 - val_matthews_correlation: 0.6088\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.65215\n",
      "Epoch 18/50\n",
      "2323/2323 [==============================] - 1s 334us/step - loss: 0.0922 - matthews_correlation: 0.6716 - val_loss: 0.1217 - val_matthews_correlation: 0.4624\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.65215\n",
      "Epoch 19/50\n",
      "2323/2323 [==============================] - 1s 334us/step - loss: 0.0952 - matthews_correlation: 0.7218 - val_loss: 0.1163 - val_matthews_correlation: 0.6569\n",
      "\n",
      "Epoch 00019: val_matthews_correlation improved from 0.65215 to 0.65691, saving model to weights_2.h5\n",
      "Epoch 20/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0889 - matthews_correlation: 0.6854 - val_loss: 0.1136 - val_matthews_correlation: 0.6249\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.65691\n",
      "Epoch 21/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0912 - matthews_correlation: 0.7262 - val_loss: 0.1580 - val_matthews_correlation: 0.3922\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.65691\n",
      "Epoch 22/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0996 - matthews_correlation: 0.6720 - val_loss: 0.1137 - val_matthews_correlation: 0.6628\n",
      "\n",
      "Epoch 00022: val_matthews_correlation improved from 0.65691 to 0.66278, saving model to weights_2.h5\n",
      "Epoch 23/50\n",
      "2323/2323 [==============================] - 1s 330us/step - loss: 0.0915 - matthews_correlation: 0.7006 - val_loss: 0.1434 - val_matthews_correlation: 0.2532\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 24/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.1596 - matthews_correlation: 0.4406 - val_loss: 0.2266 - val_matthews_correlation: 0.1560\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 25/50\n",
      "2323/2323 [==============================] - 1s 330us/step - loss: 0.1816 - matthews_correlation: 0.1297 - val_loss: 0.1476 - val_matthews_correlation: 0.4035\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 26/50\n",
      "2323/2323 [==============================] - 1s 330us/step - loss: 0.1239 - matthews_correlation: 0.5533 - val_loss: 0.1430 - val_matthews_correlation: 0.5247\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 27/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.1098 - matthews_correlation: 0.6249 - val_loss: 0.2028 - val_matthews_correlation: 0.5602\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 28/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.1280 - matthews_correlation: 0.6128 - val_loss: 0.1138 - val_matthews_correlation: 0.6489\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 29/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0949 - matthews_correlation: 0.6845 - val_loss: 0.1139 - val_matthews_correlation: 0.5587\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 30/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0925 - matthews_correlation: 0.7184 - val_loss: 0.1137 - val_matthews_correlation: 0.5458\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 31/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0905 - matthews_correlation: 0.6894 - val_loss: 0.1129 - val_matthews_correlation: 0.5423\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 32/50\n",
      "2323/2323 [==============================] - 1s 330us/step - loss: 0.0888 - matthews_correlation: 0.7285 - val_loss: 0.1126 - val_matthews_correlation: 0.5955\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2323/2323 [==============================] - 1s 330us/step - loss: 0.0841 - matthews_correlation: 0.7337 - val_loss: 0.1104 - val_matthews_correlation: 0.6461\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 34/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0844 - matthews_correlation: 0.7138 - val_loss: 0.1089 - val_matthews_correlation: 0.6531\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 35/50\n",
      "2323/2323 [==============================] - 1s 344us/step - loss: 0.0815 - matthews_correlation: 0.7463 - val_loss: 0.1067 - val_matthews_correlation: 0.6060\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.66278\n",
      "Epoch 36/50\n",
      "2323/2323 [==============================] - 1s 335us/step - loss: 0.0818 - matthews_correlation: 0.7461 - val_loss: 0.1061 - val_matthews_correlation: 0.6864\n",
      "\n",
      "Epoch 00036: val_matthews_correlation improved from 0.66278 to 0.68639, saving model to weights_2.h5\n",
      "Epoch 37/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0846 - matthews_correlation: 0.7354 - val_loss: 0.1030 - val_matthews_correlation: 0.6969\n",
      "\n",
      "Epoch 00037: val_matthews_correlation improved from 0.68639 to 0.69694, saving model to weights_2.h5\n",
      "Epoch 38/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0788 - matthews_correlation: 0.7372 - val_loss: 0.1094 - val_matthews_correlation: 0.6678\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 39/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0792 - matthews_correlation: 0.7376 - val_loss: 0.1184 - val_matthews_correlation: 0.6479\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 40/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0804 - matthews_correlation: 0.7267 - val_loss: 0.1207 - val_matthews_correlation: 0.5627\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 41/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0782 - matthews_correlation: 0.7607 - val_loss: 0.1103 - val_matthews_correlation: 0.6944\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 42/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0787 - matthews_correlation: 0.7388 - val_loss: 0.1324 - val_matthews_correlation: 0.5126\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 43/50\n",
      "2323/2323 [==============================] - 1s 334us/step - loss: 0.0739 - matthews_correlation: 0.7324 - val_loss: 0.1195 - val_matthews_correlation: 0.6398\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 44/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0787 - matthews_correlation: 0.7312 - val_loss: 0.1157 - val_matthews_correlation: 0.6074\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 45/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0758 - matthews_correlation: 0.7484 - val_loss: 0.1418 - val_matthews_correlation: 0.5371\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 46/50\n",
      "2323/2323 [==============================] - 1s 327us/step - loss: 0.0825 - matthews_correlation: 0.7497 - val_loss: 0.1237 - val_matthews_correlation: 0.5423\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 47/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0789 - matthews_correlation: 0.7436 - val_loss: 0.1298 - val_matthews_correlation: 0.5781\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 48/50\n",
      "2323/2323 [==============================] - 1s 333us/step - loss: 0.0753 - matthews_correlation: 0.7364 - val_loss: 0.1270 - val_matthews_correlation: 0.5544\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 49/50\n",
      "2323/2323 [==============================] - 1s 331us/step - loss: 0.0747 - matthews_correlation: 0.7383 - val_loss: 0.1175 - val_matthews_correlation: 0.6721\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.69694\n",
      "Epoch 50/50\n",
      "2323/2323 [==============================] - 1s 332us/step - loss: 0.0746 - matthews_correlation: 0.7278 - val_loss: 0.1115 - val_matthews_correlation: 0.6683\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.69694\n",
      "Beginning fold 4\n",
      "Train on 2324 samples, validate on 580 samples\n",
      "Epoch 1/50\n",
      "2324/2324 [==============================] - 1s 623us/step - loss: 0.3550 - matthews_correlation: 0.0097 - val_loss: 0.2286 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_3.h5\n",
      "Epoch 2/50\n",
      "2324/2324 [==============================] - 1s 346us/step - loss: 0.2302 - matthews_correlation: 0.0000e+00 - val_loss: 0.2235 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.2218 - matthews_correlation: 0.0000e+00 - val_loss: 0.2058 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.2136 - matthews_correlation: 0.0000e+00 - val_loss: 0.2078 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/50\n",
      "2324/2324 [==============================] - 1s 334us/step - loss: 0.2040 - matthews_correlation: 0.0990 - val_loss: 0.1961 - val_matthews_correlation: 0.2270\n",
      "\n",
      "Epoch 00005: val_matthews_correlation improved from 0.00000 to 0.22696, saving model to weights_3.h5\n",
      "Epoch 6/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.1959 - matthews_correlation: 0.1117 - val_loss: 0.1742 - val_matthews_correlation: 0.1559\n",
      "\n",
      "Epoch 00006: val_matthews_correlation did not improve from 0.22696\n",
      "Epoch 7/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.1923 - matthews_correlation: 0.1851 - val_loss: 0.2097 - val_matthews_correlation: 0.2741\n",
      "\n",
      "Epoch 00007: val_matthews_correlation improved from 0.22696 to 0.27415, saving model to weights_3.h5\n",
      "Epoch 8/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.1779 - matthews_correlation: 0.1321 - val_loss: 0.1680 - val_matthews_correlation: 0.2741\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.27415\n",
      "Epoch 9/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.1579 - matthews_correlation: 0.2082 - val_loss: 0.1413 - val_matthews_correlation: 0.4053\n",
      "\n",
      "Epoch 00009: val_matthews_correlation improved from 0.27415 to 0.40533, saving model to weights_3.h5\n",
      "Epoch 10/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.1314 - matthews_correlation: 0.6097 - val_loss: 0.1400 - val_matthews_correlation: 0.4000\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.40533\n",
      "Epoch 11/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.1262 - matthews_correlation: 0.4405 - val_loss: 0.1103 - val_matthews_correlation: 0.4346\n",
      "\n",
      "Epoch 00011: val_matthews_correlation improved from 0.40533 to 0.43463, saving model to weights_3.h5\n",
      "Epoch 12/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.1087 - matthews_correlation: 0.6273 - val_loss: 0.1096 - val_matthews_correlation: 0.5750\n",
      "\n",
      "Epoch 00012: val_matthews_correlation improved from 0.43463 to 0.57497, saving model to weights_3.h5\n",
      "Epoch 13/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.1030 - matthews_correlation: 0.6344 - val_loss: 0.1543 - val_matthews_correlation: 0.3246\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.57497\n",
      "Epoch 14/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.1176 - matthews_correlation: 0.6159 - val_loss: 0.1244 - val_matthews_correlation: 0.6490\n",
      "\n",
      "Epoch 00014: val_matthews_correlation improved from 0.57497 to 0.64898, saving model to weights_3.h5\n",
      "Epoch 15/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0992 - matthews_correlation: 0.6602 - val_loss: 0.1070 - val_matthews_correlation: 0.5712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.64898\n",
      "Epoch 16/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.1016 - matthews_correlation: 0.6747 - val_loss: 0.1069 - val_matthews_correlation: 0.5795\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.64898\n",
      "Epoch 17/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.1025 - matthews_correlation: 0.6496 - val_loss: 0.1014 - val_matthews_correlation: 0.6322\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.64898\n",
      "Epoch 18/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.1083 - matthews_correlation: 0.5938 - val_loss: 0.1100 - val_matthews_correlation: 0.5345\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.64898\n",
      "Epoch 19/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.1095 - matthews_correlation: 0.5836 - val_loss: 0.1065 - val_matthews_correlation: 0.6331\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.64898\n",
      "Epoch 20/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.1037 - matthews_correlation: 0.6338 - val_loss: 0.1085 - val_matthews_correlation: 0.7039\n",
      "\n",
      "Epoch 00020: val_matthews_correlation improved from 0.64898 to 0.70386, saving model to weights_3.h5\n",
      "Epoch 21/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.1043 - matthews_correlation: 0.6513 - val_loss: 0.1088 - val_matthews_correlation: 0.4636\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 22/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.1238 - matthews_correlation: 0.4143 - val_loss: 0.1092 - val_matthews_correlation: 0.4552\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 23/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.1050 - matthews_correlation: 0.6027 - val_loss: 0.1047 - val_matthews_correlation: 0.5917\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 24/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.0972 - matthews_correlation: 0.6852 - val_loss: 0.1025 - val_matthews_correlation: 0.5917\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 25/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.0984 - matthews_correlation: 0.6648 - val_loss: 0.1039 - val_matthews_correlation: 0.5254\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 26/50\n",
      "2324/2324 [==============================] - 1s 335us/step - loss: 0.0985 - matthews_correlation: 0.6893 - val_loss: 0.1029 - val_matthews_correlation: 0.6092\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 27/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.0905 - matthews_correlation: 0.7136 - val_loss: 0.1178 - val_matthews_correlation: 0.4828\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 28/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.0913 - matthews_correlation: 0.7056 - val_loss: 0.1057 - val_matthews_correlation: 0.4816\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 29/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.0918 - matthews_correlation: 0.6832 - val_loss: 0.1166 - val_matthews_correlation: 0.4828\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 30/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0918 - matthews_correlation: 0.6624 - val_loss: 0.1056 - val_matthews_correlation: 0.5582\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 31/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.1026 - matthews_correlation: 0.6784 - val_loss: 0.1050 - val_matthews_correlation: 0.5978\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 32/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.0928 - matthews_correlation: 0.7037 - val_loss: 0.1064 - val_matthews_correlation: 0.4960\n",
      "\n",
      "Epoch 00032: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 33/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.0910 - matthews_correlation: 0.7006 - val_loss: 0.1045 - val_matthews_correlation: 0.5842\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 34/50\n",
      "2324/2324 [==============================] - 1s 334us/step - loss: 0.0903 - matthews_correlation: 0.6986 - val_loss: 0.1281 - val_matthews_correlation: 0.4928\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 35/50\n",
      "2324/2324 [==============================] - 1s 327us/step - loss: 0.0989 - matthews_correlation: 0.6676 - val_loss: 0.1097 - val_matthews_correlation: 0.5528\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 36/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.0942 - matthews_correlation: 0.6598 - val_loss: 0.1089 - val_matthews_correlation: 0.5590\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 37/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0915 - matthews_correlation: 0.7012 - val_loss: 0.1042 - val_matthews_correlation: 0.5533\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 38/50\n",
      "2324/2324 [==============================] - 1s 334us/step - loss: 0.0891 - matthews_correlation: 0.7083 - val_loss: 0.1142 - val_matthews_correlation: 0.5720\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 39/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0889 - matthews_correlation: 0.6551 - val_loss: 0.1047 - val_matthews_correlation: 0.5851\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 40/50\n",
      "2324/2324 [==============================] - 1s 334us/step - loss: 0.0863 - matthews_correlation: 0.6747 - val_loss: 0.1079 - val_matthews_correlation: 0.5967\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 41/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.0910 - matthews_correlation: 0.6872 - val_loss: 0.1098 - val_matthews_correlation: 0.5668\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 42/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0942 - matthews_correlation: 0.7036 - val_loss: 0.1116 - val_matthews_correlation: 0.5535\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 43/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0897 - matthews_correlation: 0.6708 - val_loss: 0.1082 - val_matthews_correlation: 0.5960\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 44/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.0889 - matthews_correlation: 0.6808 - val_loss: 0.1078 - val_matthews_correlation: 0.5917\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 45/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.0901 - matthews_correlation: 0.6617 - val_loss: 0.1098 - val_matthews_correlation: 0.5479\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 46/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.0876 - matthews_correlation: 0.6946 - val_loss: 0.1233 - val_matthews_correlation: 0.4798\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 47/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0962 - matthews_correlation: 0.6834 - val_loss: 0.1085 - val_matthews_correlation: 0.5937\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 48/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0909 - matthews_correlation: 0.7134 - val_loss: 0.1008 - val_matthews_correlation: 0.6827\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 49/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.0859 - matthews_correlation: 0.6888 - val_loss: 0.1117 - val_matthews_correlation: 0.5498\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.70386\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.0859 - matthews_correlation: 0.6702 - val_loss: 0.1242 - val_matthews_correlation: 0.4731\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.70386\n",
      "Beginning fold 5\n",
      "Train on 2324 samples, validate on 580 samples\n",
      "Epoch 1/50\n",
      "2324/2324 [==============================] - 2s 682us/step - loss: 0.3266 - matthews_correlation: 0.0000e+00 - val_loss: 0.2217 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_matthews_correlation improved from -inf to 0.00000, saving model to weights_4.h5\n",
      "Epoch 2/50\n",
      "2324/2324 [==============================] - 1s 345us/step - loss: 0.2236 - matthews_correlation: 0.0000e+00 - val_loss: 0.1942 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 3/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.2023 - matthews_correlation: 0.0000e+00 - val_loss: 0.1896 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 4/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.1776 - matthews_correlation: 0.1158 - val_loss: 0.1697 - val_matthews_correlation: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_matthews_correlation did not improve from 0.00000\n",
      "Epoch 5/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.1552 - matthews_correlation: 0.2451 - val_loss: 0.1688 - val_matthews_correlation: 0.4617\n",
      "\n",
      "Epoch 00005: val_matthews_correlation improved from 0.00000 to 0.46168, saving model to weights_4.h5\n",
      "Epoch 6/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.1295 - matthews_correlation: 0.4292 - val_loss: 0.1343 - val_matthews_correlation: 0.5591\n",
      "\n",
      "Epoch 00006: val_matthews_correlation improved from 0.46168 to 0.55912, saving model to weights_4.h5\n",
      "Epoch 7/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.1132 - matthews_correlation: 0.5851 - val_loss: 0.1457 - val_matthews_correlation: 0.3454\n",
      "\n",
      "Epoch 00007: val_matthews_correlation did not improve from 0.55912\n",
      "Epoch 8/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.1199 - matthews_correlation: 0.6011 - val_loss: 0.1287 - val_matthews_correlation: 0.4685\n",
      "\n",
      "Epoch 00008: val_matthews_correlation did not improve from 0.55912\n",
      "Epoch 9/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.1130 - matthews_correlation: 0.5796 - val_loss: 0.1127 - val_matthews_correlation: 0.6597\n",
      "\n",
      "Epoch 00009: val_matthews_correlation improved from 0.55912 to 0.65972, saving model to weights_4.h5\n",
      "Epoch 10/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0985 - matthews_correlation: 0.6612 - val_loss: 0.1104 - val_matthews_correlation: 0.5067\n",
      "\n",
      "Epoch 00010: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 11/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.1013 - matthews_correlation: 0.6708 - val_loss: 0.1087 - val_matthews_correlation: 0.6299\n",
      "\n",
      "Epoch 00011: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 12/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.1011 - matthews_correlation: 0.6424 - val_loss: 0.1109 - val_matthews_correlation: 0.5769\n",
      "\n",
      "Epoch 00012: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 13/50\n",
      "2324/2324 [==============================] - 1s 343us/step - loss: 0.0969 - matthews_correlation: 0.6734 - val_loss: 0.1155 - val_matthews_correlation: 0.6299\n",
      "\n",
      "Epoch 00013: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 14/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.1029 - matthews_correlation: 0.6509 - val_loss: 0.1137 - val_matthews_correlation: 0.6431\n",
      "\n",
      "Epoch 00014: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 15/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0970 - matthews_correlation: 0.6791 - val_loss: 0.1191 - val_matthews_correlation: 0.4950\n",
      "\n",
      "Epoch 00015: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 16/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.0933 - matthews_correlation: 0.6981 - val_loss: 0.1189 - val_matthews_correlation: 0.6456\n",
      "\n",
      "Epoch 00016: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 17/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.1095 - matthews_correlation: 0.6264 - val_loss: 0.1114 - val_matthews_correlation: 0.6447\n",
      "\n",
      "Epoch 00017: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 18/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.0931 - matthews_correlation: 0.6387 - val_loss: 0.1086 - val_matthews_correlation: 0.5584\n",
      "\n",
      "Epoch 00018: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 19/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0935 - matthews_correlation: 0.7168 - val_loss: 0.1091 - val_matthews_correlation: 0.5242\n",
      "\n",
      "Epoch 00019: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 20/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0940 - matthews_correlation: 0.6937 - val_loss: 0.1103 - val_matthews_correlation: 0.6175\n",
      "\n",
      "Epoch 00020: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 21/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.0886 - matthews_correlation: 0.7155 - val_loss: 0.1182 - val_matthews_correlation: 0.4987\n",
      "\n",
      "Epoch 00021: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 22/50\n",
      "2324/2324 [==============================] - 1s 334us/step - loss: 0.0944 - matthews_correlation: 0.6481 - val_loss: 0.1049 - val_matthews_correlation: 0.6172\n",
      "\n",
      "Epoch 00022: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 23/50\n",
      "2324/2324 [==============================] - 1s 327us/step - loss: 0.0878 - matthews_correlation: 0.6903 - val_loss: 0.1230 - val_matthews_correlation: 0.5818\n",
      "\n",
      "Epoch 00023: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 24/50\n",
      "2324/2324 [==============================] - 1s 334us/step - loss: 0.1170 - matthews_correlation: 0.6162 - val_loss: 0.1086 - val_matthews_correlation: 0.4249\n",
      "\n",
      "Epoch 00024: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 25/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0997 - matthews_correlation: 0.6675 - val_loss: 0.1144 - val_matthews_correlation: 0.4254\n",
      "\n",
      "Epoch 00025: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 26/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.0981 - matthews_correlation: 0.5979 - val_loss: 0.1068 - val_matthews_correlation: 0.6223\n",
      "\n",
      "Epoch 00026: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 27/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0976 - matthews_correlation: 0.6439 - val_loss: 0.1091 - val_matthews_correlation: 0.5431\n",
      "\n",
      "Epoch 00027: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 28/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0907 - matthews_correlation: 0.6727 - val_loss: 0.1075 - val_matthews_correlation: 0.6131\n",
      "\n",
      "Epoch 00028: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 29/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0887 - matthews_correlation: 0.6668 - val_loss: 0.1059 - val_matthews_correlation: 0.6248\n",
      "\n",
      "Epoch 00029: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 30/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.0888 - matthews_correlation: 0.6949 - val_loss: 0.1095 - val_matthews_correlation: 0.6037\n",
      "\n",
      "Epoch 00030: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 31/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0892 - matthews_correlation: 0.6860 - val_loss: 0.1115 - val_matthews_correlation: 0.4594\n",
      "\n",
      "Epoch 00031: val_matthews_correlation did not improve from 0.65972\n",
      "Epoch 32/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.0871 - matthews_correlation: 0.6920 - val_loss: 0.1142 - val_matthews_correlation: 0.6602\n",
      "\n",
      "Epoch 00032: val_matthews_correlation improved from 0.65972 to 0.66025, saving model to weights_4.h5\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0857 - matthews_correlation: 0.7079 - val_loss: 0.1090 - val_matthews_correlation: 0.5262\n",
      "\n",
      "Epoch 00033: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 34/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0841 - matthews_correlation: 0.7216 - val_loss: 0.1107 - val_matthews_correlation: 0.6093\n",
      "\n",
      "Epoch 00034: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 35/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0853 - matthews_correlation: 0.7037 - val_loss: 0.1107 - val_matthews_correlation: 0.5385\n",
      "\n",
      "Epoch 00035: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 36/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.0838 - matthews_correlation: 0.7121 - val_loss: 0.1077 - val_matthews_correlation: 0.5856\n",
      "\n",
      "Epoch 00036: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 37/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0905 - matthews_correlation: 0.6949 - val_loss: 0.1226 - val_matthews_correlation: 0.6400\n",
      "\n",
      "Epoch 00037: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 38/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.0894 - matthews_correlation: 0.6656 - val_loss: 0.1160 - val_matthews_correlation: 0.4368\n",
      "\n",
      "Epoch 00038: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 39/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.0863 - matthews_correlation: 0.6425 - val_loss: 0.1102 - val_matthews_correlation: 0.6320\n",
      "\n",
      "Epoch 00039: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 40/50\n",
      "2324/2324 [==============================] - 1s 330us/step - loss: 0.0862 - matthews_correlation: 0.6531 - val_loss: 0.1094 - val_matthews_correlation: 0.5777\n",
      "\n",
      "Epoch 00040: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 41/50\n",
      "2324/2324 [==============================] - 1s 333us/step - loss: 0.0835 - matthews_correlation: 0.7288 - val_loss: 0.1183 - val_matthews_correlation: 0.6472\n",
      "\n",
      "Epoch 00041: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 42/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.0857 - matthews_correlation: 0.7120 - val_loss: 0.1073 - val_matthews_correlation: 0.5722\n",
      "\n",
      "Epoch 00042: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 43/50\n",
      "2324/2324 [==============================] - 1s 329us/step - loss: 0.0878 - matthews_correlation: 0.6839 - val_loss: 0.1227 - val_matthews_correlation: 0.5962\n",
      "\n",
      "Epoch 00043: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 44/50\n",
      "2324/2324 [==============================] - 1s 334us/step - loss: 0.0928 - matthews_correlation: 0.6867 - val_loss: 0.1197 - val_matthews_correlation: 0.5583\n",
      "\n",
      "Epoch 00044: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 45/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0822 - matthews_correlation: 0.7305 - val_loss: 0.1125 - val_matthews_correlation: 0.6602\n",
      "\n",
      "Epoch 00045: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 46/50\n",
      "2324/2324 [==============================] - 1s 332us/step - loss: 0.0809 - matthews_correlation: 0.7483 - val_loss: 0.1179 - val_matthews_correlation: 0.4315\n",
      "\n",
      "Epoch 00046: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 47/50\n",
      "2324/2324 [==============================] - 1s 331us/step - loss: 0.0796 - matthews_correlation: 0.7179 - val_loss: 0.1126 - val_matthews_correlation: 0.5911\n",
      "\n",
      "Epoch 00047: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 48/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.0776 - matthews_correlation: 0.7287 - val_loss: 0.1102 - val_matthews_correlation: 0.6114\n",
      "\n",
      "Epoch 00048: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 49/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.0792 - matthews_correlation: 0.7120 - val_loss: 0.1178 - val_matthews_correlation: 0.6023\n",
      "\n",
      "Epoch 00049: val_matthews_correlation did not improve from 0.66025\n",
      "Epoch 50/50\n",
      "2324/2324 [==============================] - 1s 328us/step - loss: 0.0784 - matthews_correlation: 0.7190 - val_loss: 0.1080 - val_matthews_correlation: 0.6023\n",
      "\n",
      "Epoch 00050: val_matthews_correlation did not improve from 0.66025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2904,), (2904,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, create a set of indexes of the 5 folds\n",
    "splits = list(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=2019).split(X, y))\n",
    "preds_val = []\n",
    "y_val = []\n",
    "# Then, iteract with each fold\n",
    "# If you dont know, enumerate(['a', 'b', 'c']) returns [(0, 'a'), (1, 'b'), (2, 'c')]\n",
    "for idx, (train_idx, val_idx) in enumerate(splits):\n",
    "    K.clear_session() # I dont know what it do, but I imagine that it \"clear session\" :)\n",
    "    print(\"Beginning fold {}\".format(idx+1))\n",
    "    # use the indexes to extract the folds in the train and validation data\n",
    "    train_X, train_y, val_X, val_y = X[train_idx], y[train_idx], X[val_idx], y[val_idx]\n",
    "    # instantiate the model for this fold\n",
    "    model = model_lstm(train_X.shape)\n",
    "    # This checkpoint helps to avoid overfitting. It just save the weights of the model if it delivered an\n",
    "    # validation matthews_correlation greater than the last one.\n",
    "    ckpt = ModelCheckpoint('weights_{}.h5'.format(idx), save_best_only=True, save_weights_only=True, verbose=1, monitor='val_matthews_correlation', mode='max')\n",
    "    # Train, train, train\n",
    "    model.fit(train_X, train_y, batch_size=128, epochs=50, validation_data=[val_X, val_y], callbacks=[ckpt])\n",
    "    # loads the best weights saved by the checkpoint\n",
    "    model.load_weights('weights_{}.h5'.format(idx))\n",
    "    # Add the predictions of the validation to the list preds_val\n",
    "    preds_val.append(model.predict(val_X, batch_size=512))\n",
    "    # and the val true y\n",
    "    y_val.append(val_y)\n",
    "\n",
    "# concatenates all and prints the shape    \n",
    "preds_val = np.concatenate(preds_val)[...,0]\n",
    "y_val = np.concatenate(y_val)\n",
    "preds_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# The output of this kernel must be binary (0 or 1), but the output of the NN Model is float (0 to 1).\n",
    "# So, find the best threshold to convert float to binary is crucial to the result\n",
    "# this piece of code is a function that evaluates all the possible thresholds from 0 to 1 by 0.01\n",
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in tqdm([i * 0.01 for i in range(100)]):\n",
    "        score = K.eval(matthews_correlation(K.variable(y_true.astype(np.float64)), K.variable((y_proba > threshold).astype(np.float64))))\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'matthews_correlation': best_score}\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  5.98it/s]\n"
     ]
    }
   ],
   "source": [
    "best_threshold = threshold_search(y_val, preds_val)['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 4.74 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Now load the test data\n",
    "# This first part is the meta data, not the main data, the measurements\n",
    "meta_test = pd.read_csv('../input/metadata_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signal_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>2904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>2904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8714</th>\n",
       "      <td>2904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>2905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>2905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_measurement  phase\n",
       "signal_id                       \n",
       "8712                 2904      0\n",
       "8713                 2904      1\n",
       "8714                 2904      2\n",
       "8715                 2905      0\n",
       "8716                 2905      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test = meta_test.set_index(['signal_id'])\n",
    "meta_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8712 10 20337 2033 7 20337\n",
      "[[8712, 10745], [10745, 12778], [12778, 14811], [14811, 16844], [16844, 18877], [18877, 20910], [20910, 22943], [22943, 24976], [24976, 27009], [27009, 29042], [29042, 29049]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2033/2033 [01:47<00:00, 18.88it/s]\n",
      "100%|██████████| 2033/2033 [01:47<00:00, 18.94it/s]\n",
      "100%|██████████| 2033/2033 [01:48<00:00, 18.65it/s]\n",
      "100%|██████████| 2033/2033 [01:47<00:00, 18.85it/s]\n",
      "100%|██████████| 2033/2033 [01:46<00:00, 19.03it/s]\n",
      "100%|██████████| 2033/2033 [01:48<00:00, 18.81it/s]\n",
      "100%|██████████| 2033/2033 [01:46<00:00, 19.15it/s]\n",
      "100%|██████████| 2033/2033 [01:47<00:00, 18.95it/s]\n",
      "100%|██████████| 2033/2033 [01:46<00:00, 19.04it/s]\n",
      "100%|██████████| 2033/2033 [01:48<00:00, 18.75it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 57s, sys: 10.1 s, total: 19min 7s\n",
      "Wall time: 19min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# First we daclarete a series of parameters to initiate the loading of the main data\n",
    "# it is too large, it is impossible to load in one time, so we are doing it in dividing in 10 parts\n",
    "first_sig = meta_test.index[0]\n",
    "n_parts = 10\n",
    "max_line = len(meta_test)\n",
    "part_size = int(max_line / n_parts)\n",
    "last_part = max_line % n_parts\n",
    "print(first_sig, n_parts, max_line, part_size, last_part, n_parts * part_size + last_part)\n",
    "# Here we create a list of lists with start index and end index for each of the 10 parts and one for the last partial part\n",
    "start_end = [[x, x+part_size] for x in range(first_sig, max_line + first_sig, part_size)]\n",
    "start_end = start_end[:-1] + [[start_end[-1][0], start_end[-1][0] + last_part]]\n",
    "print(start_end)\n",
    "X_test = []\n",
    "# now, very like we did above with the train data, we convert the test data part by part\n",
    "# transforming the 3 phases 800000 measurement in matrix (160,57)\n",
    "for start, end in start_end:\n",
    "    subset_test = pq.read_pandas('../input/test.parquet', columns=[str(i) for i in range(start, end)]).to_pandas()\n",
    "    for i in tqdm(subset_test.columns):\n",
    "        id_measurement, phase = meta_test.loc[int(i)]\n",
    "        subset_test_col = subset_test[i]\n",
    "        subset_trans = transform_ts(subset_test_col)\n",
    "        X_test.append([i, id_measurement, phase, subset_trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6779, 160, 57)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_input = np.asarray([np.concatenate([X_test[i][3],X_test[i+1][3], X_test[i+2][3]], axis=1) for i in range(0,len(X_test), 3)])\n",
    "np.save(\"X_test.npy\",X_test_input)\n",
    "X_test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id  target\n",
       "0       8712       0\n",
       "1       8713       0\n",
       "2       8714       0\n",
       "3       8715       0\n",
       "4       8716       0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "print(len(submission))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6779/6779 [==============================] - 1s 93us/step\n",
      "6779/6779 [==============================] - 1s 86us/step\n",
      "6779/6779 [==============================] - 1s 87us/step\n",
      "6779/6779 [==============================] - 1s 87us/step\n",
      "6779/6779 [==============================] - 1s 87us/step\n"
     ]
    }
   ],
   "source": [
    "preds_test = []\n",
    "for i in range(N_SPLITS):\n",
    "    model.load_weights('weights_{}.h5'.format(i))\n",
    "    pred = model.predict(X_test_input, batch_size=300, verbose=1)\n",
    "    pred_3 = []\n",
    "    for pred_scalar in pred:\n",
    "        for i in range(3):\n",
    "            pred_3.append(pred_scalar)\n",
    "    preds_test.append(pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20337,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test = (np.squeeze(np.mean(preds_test, axis=0)) > best_threshold).astype(np.int)\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id  target\n",
       "0       8712       0\n",
       "1       8713       0\n",
       "2       8714       0\n",
       "3       8715       0\n",
       "4       8716       0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'] = preds_test\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
